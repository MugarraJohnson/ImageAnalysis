reticulate::repl_python()
reticulate::repl_python()
import numpy as np
import numpy as np
import numpy as np
import numpy as np
import numpy as np
import scikit-learn
import numpy as np
import scikitlearn
quit
im <- image.open(file.choose())
reticulate::repl_python()
import numpy as np
quit
im <- image.open(file.choose())
reticulate::repl_python()
import numpy as np
from PIL import Image
quit
im <- image.open(file.choose())
im <- image.open(file.choose())
im <- Image.open(file.choose())
reticulate::repl_python()
import numpy as np
from PIL import Image
im <- Image.open(file.choose())
im <- Image.open("D:\OneDrive\Pictures\IMG_0441 1.jpeg")
im <- Image.open("D:/OneDrive/Pictures/IMG_0441 1.jpeg")
im = Image.open("D:/OneDrive/Pictures/IMG_0441 1.jpeg")
im = Image.open("D:/OneDrive/Pictures/IMG_0441 1.jpeg")
img = Image.open("D:/OneDrive/Pictures/IMG_0441 1.jpeg")
View(im)
drop(im)
remove(im)
img_gray = img.convert('L')
import numpy as np
from PIL import Image
X = np.array(img)
X = np.array(img)
print(X.shape)
Y = np.array(img_gray)
print(Y.shape)
Z = X.flatten()
print(Z.shape)
img.show()
tfds.as_dataframe(
ds: tf.data.Dataset, ds_info: Optional[dataset_info.DatasetInfo] = None
) -> pd.DataFrame
import numpy as np
from PIL import Image
import pandas as pd
import numpy as np
from PIL import Image
import pandas as pd
tfds.as_dataframe(
ds: tf.data.Dataset, ds_info: Optional[dataset_info.DatasetInfo] = None
) -> pd.DataFrame
reticulate::repl_python()
import numpy as np
a = np.array([1,2,3,4,5])
np.linalg.norm(a)
a = np.array([1,2,3,4,5])
b = np.array([5,6,7,8,9])
np.dot(a,b)
np.dot(a,b)/(np.linalg.norm(a)*np.linalg.norm(b))
a = wiki.page('jungle book', auto_suggest = False)
import numpy as np
import wikipedia as wiki
a = wiki.page('jungle book', auto_suggest = False)
a = wiki.page('jungle book', auto_suggest = False)
b = wiki.page('Harry Potter', auto_suggest = False)
a = wiki.page('jungle book', auto_suggest = False)
b = wiki.page('Harry Potter', auto_suggest = False)
c = wiki.page('Tarzan', auto_suggest = False)
print(a.content.split())
print(a.content.split())
print(b.content.split())
print(c.content.split())
print(len(a.content.split()))
print(len(b.content.split()))
print(len(c.content.split()))
from sklearn.feature_extraction.text import CountVectorizer, TfidVectorizer
from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer
